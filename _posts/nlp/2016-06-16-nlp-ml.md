---
layout: post
title: 《机器学习实战》笔记
category: nlp
comments: false
---

# 什么是机器学习

## 概述
机器学习是为了把无序的数据转换成有用的信息，横跨CS，工程技术和统计学等多个学科。

Langley（1996) 定义的机器学习是“机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能，特别是如何在经验学习中改善具体算法的性能”。

Machine learning is a science of the artificial. The field's main objects of study are artifacts, specifically algorithms that improve their performance with experience.

## 机器学习的主要任务
对于分类问题，ML的主要任务是将实例数据划分到合适的分类中。（变量是离散型的：是/否，A/B/C)  
对于预测问题，ML的主要任务是回归，得到数据型数据。(变量是连续型的：0.0~100.0)

## 监督学习
分类和回归属于监督学习，因为这类算法必须知道预测什么，即目标变量的分类信息。

## 无监督学习
此时数据没有类别信息，也不会给定目标值。（不是用于预测值的）  
在无监督学习中，将数据集合分成由类似的对象组成的多个类的过程被称为**聚类**；将寻找描述数据统计值的过程称之为**密度估计**（估计数据与每个分组的相似程
度）。  
此外，无监督学习还可以减少数据特征的维度，以便我们可以使用二维或三维图形更加直观地展示数据信息。

监督学习的用途 

算法| 用途
-----|------
K-近邻算法		|线性回归
朴素贝叶斯算法	|局部加权线性回归
支持向量机		|Ridge回归
决策树Lasso		|最小回归系数估计


无监督学习的用途

算法| 用途
-----|------
K-均值			|最大期望算法
DBSCAN			|Parzen窗设计

## 开发机器学习应用程序的步骤
1. 收集数据。如：制作网络爬虫从网站上抽取数据、
从&38反馈或者八?1中得到信息、设备发送过来的实测数据（风速、血糖等)。或者使用公开数据。

2. 准备输入数据。格式化、结构化数据。

3. 分析输入数据。人工分析先前得到的数据，确保没有垃圾数据。如看数据是否合理，有无异常值，能否预测到目标数据。通常和2一起处理。

4. 训练算法。将得到知识存储为计算机可以处理的格式。如果使用无监督学习算法，由于不存在目标变量值，故而也不需要训练算法。

5. 测试算法。为了评估算法，需要测试算法的工作效果。对于监督学习，必须已知用于评估算法的目标变量值；对于无监督学习，也必须用其他的评测手段来检验算法的成功率。无论哪种情形，如果不满意算法的输出结果，则可以回到第4步，改正并加以测试。

6. 使用算法。将机器学习算法转换为应用程序，执行实际任务，以检验上述步骤是否可以
在实际环境中正常工作。

# K-近邻算法 （Chapter 2）
简单地说，k-近邻算法采用测量不同特征值之间的距离方法进行分类。


## 概述
优点：精度高、对异常值不敏感、无数据输入假定。  
缺点：计算复杂度高、空间复杂度高。  
适用数据范围：数值型和标称型。

KNN算法工作原理：存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据与所属分类的对应关系。输人没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。
一般来说，我们只选择样本数据集中前k个最相似的数据，这就是k-近邻算法中k的出处,通常k是不大于20的整数。最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。

不需要训练算法。

为了测试分类器的效果，我们可以使用已知答案的数据，当然答案不能告诉分类器，检验分类器给出的结果是否符合预期结果。通过大量的测试数据，我们可以得到分类器的错误率— 分类器给出错误结果的次数除以测试执行的总数。错误率是常用的评估方法，主要用于评估分类器在某个数据集上的执行效果。

## 实例
- 约会系统
- 识别手写

## 小结
- k-近邻算法是分类数据最简单最有效的算法。
- k-近邻算法是基于实例的学习，使用算法时我们必须有接近实际数据的训练样本数据。
- k-近邻算法必须保存全部数据集，如果训练数据集的很大，必须使用大量的存储空间。
- 此外,由于必须对数据集中的每个数据计算距离值，实际使用时可能非常耗时。
- k-近邻算法的另一个缺陷是它无法给出任何数据的基础结构信息，因此我们也无法知晓平均实例样本和典型实例样本具有什么特征。

# 决策树 （Chapter 3）
决策树的工作原理和读心机器人的原理类似。常用于处理分类问题。门槛低。

## 构造决策树
最大的缺点是无法给出数据的内在含义，决策树的主要优势就在于数据形式非常容易理解。

优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据。  
缺点：可能会产生过度匹配问题。  
适用数据类型：数值型和标称型。

划分数据集的大原则是：将无序的数据变得更加有序。

组织杂乱无章数据的一种方法就是使用信息论度量信息，信息论是量化处理信息的分支科学。